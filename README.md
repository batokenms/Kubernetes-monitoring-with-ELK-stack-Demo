# Notes 

# The deployment order doesn't matter; however, you should follow this order. 

1. elasticsearch-ss.yaml
2. logstash-deployment.yaml
3. filebeat-ds.yaml            ==>  ds stands for daemon set
4. metricbeat-ds.yaml          ==>  ds stands for daemon set
5. kibana-deployment.yaml
6. curator-cronjob.yaml
=================================================================================================================================
Elasticsearch

What is elasticsearch and why is it important to DevOps engineers in Kubernetes?

Imagine you have a huge pile of documents, thousands or even millions of them, and you need to find a specific document quickly. It would be a challenging task if you had to manually search through all the documents, right? This is where Elasticsearch comes in.

Elasticsearch is an open-source search and analytics engine. It is designed to help you store, search, and analyze large amounts of data quickly and efficiently. It is part of the Elastic Stack, which also includes Logstash for data ingestion and Kibana for data visualization.

In the context of Kubernetes, DevOps engineers often deal with complex applications and microservices that generate a massive amount of log files, metrics, and other data. Elasticsearch can be integrated into Kubernetes environments to centralize and index this data, making it searchable and providing valuable insights.

Here is why Elasticsearch is important to DevOps engineers in Kubernetes:

1.	Log Management: In Kubernetes, multiple containers and nodes generate logs. Elasticsearch can collect and store these logs from various sources, making it easier to search, analyze, and troubleshoot issues within the Kubernetes cluster.
   
3.	Monitoring and Alerting: Elasticsearch can ingest metrics from Kubernetes components, such as nodes, pods, and services. DevOps engineers can then create visualizations, dashboards, and set up alerts based on these metrics to monitor the health and performance of their Kubernetes infrastructure.
   
5.	Centralized Search: Elasticsearch enables DevOps engineers to search across all the logs and metrics in a Kubernetes environment quickly. This helps in identifying patterns, finding specific events, and troubleshooting problems efficiently.
   
7.	Scalability and Resilience: Kubernetes is known for its ability to scale applications. Similarly, Elasticsearch is horizontally scalable, meaning you can add more Elasticsearch nodes to distribute the data and workload. This scalability ensures that Elasticsearch can handle large volumes of data generated by Kubernetes.
   
9.	Integration with the Elastic Stack: Elasticsearch integrates seamlessly with other components of the Elastic Stack. Logstash can be used to collect, filter, and transform data before sending it to Elasticsearch. Kibana provides a user-friendly interface for visualizing and analyzing the data stored in Elasticsearch.
    
In summary, Elasticsearch is important to DevOps engineers in Kubernetes because it helps them manage and analyze the vast amount of data generated by Kubernetes applications. It simplifies log management, enables monitoring and alerting, provides centralized search capabilities, and integrates well with the rest of the Elastic Stack, making it a powerful tool for DevOps tasks in Kubernetes environments.

===============================================================================================================================


# What is a DaemonSet in Kubernetes? 

A DaemonSet in Kubernetes is a type of controller that ensures that a copy of a specific pod is running on each node in the cluster. 

It is used for running system daemons or background processes that must be present on every node.

Here are a few critical points about DaemonSets and their importance:

Placement on every node: DaemonSets ensure that a copy of the specified pod runs on each node in the cluster. 

This makes them helpful in deploying specific infrastructure-related tasks or agents that must be present on every node, such as log collectors, monitoring agents, or networking components.

Scaling with the cluster: As you add or remove nodes from the cluster, DaemonSets automatically adjust to maintain the desired number of pods. 

When a new node joins the cluster, a pod is automatically created on that node. If a node is removed, the corresponding pod is also removed.

Updating or rolling out changes: DaemonSets provide a way to easily update or roll out changes to the pods running on each node. 

When you update the DaemonSet's configuration, such as the container image or resource requirements, Kubernetes automatically handles rolling updates, ensuring that the new configuration is applied to each pod while maintaining the desired number of replicas.

Node-specific configurations: DaemonSets can apply node-specific configurations or deploy node-specific services. 

Using node labels or node selectors, you can customize the pods running on specific nodes, enabling you to deploy different configurations or services based on the node's characteristics.

Monitoring and logging: DaemonSets are crucial in ensuring proper monitoring and logging across the cluster. By running monitoring agents or log collectors as DaemonSets, you can collect metrics and logs from every node, providing comprehensive visibility into the cluster's health and performance.

DaemonSets are essential for deploying and managing system-level processes or agents across all nodes in a Kubernetes cluster. They simplify the deployment and management of infrastructure-related components, provide consistency across the cluster, and enable efficient monitoring and logging practices.

# Images from the above project 

#Workloads 

![image](https://github.com/joshking1/Kubernetes-monitoring-with-ELK-stack-Demo/assets/88409463/c8da6da5-ba27-45b2-9b93-0c570284c741)


#Services & Ingress 
![image](https://github.com/joshking1/Kubernetes-monitoring-with-ELK-stack-Demo/assets/88409463/697ccb36-f0b9-4540-ab51-7d4092adb0a4)


# Deploying a stateful application

Stateful applications save data to persistent disk storage for the server, clients, and other applications. 

An example of a stateful application is a database or key-value store to which other applications save and retrieve data.

Persistent storage can be dynamically provisioned, creating the underlying volumes on demand. 

In Kubernetes, you configure dynamic provisioning by creating a StorageClass. 

In GKE, a default StorageClass allows you to dynamically provision Compute Engine persistent disks.

Kubernetes uses the StatefulSet controller to deploy stateful applications as StatefulSet objects. 

Pods in StatefulSets are not interchangeable: each Pod has a unique identifier maintained no matter where it is scheduled.

Stateful applications differ from stateless applications, in which client data is not saved to the server between sessions.

# Deploying a stateless application 

# Deploying a stateless Linux application

Stateless applications do not store data or application state to the cluster or persistent storage. 

Instead, data and application states stay with the client, which makes stateless applications more scalable. 

For example, a frontend application is stateless: you deploy multiple replicas to increase its availability and scale down when demand is low, and the replicas do not need unique identities.

Kubernetes uses the Deployment controller to deploy stateless applications as uniform, non-unique Pods. 

Deployments manage the desired state of your application: how many Pods should run your application, what version of the container image should run, what the Pods should be labeled, and so on. The desired state can be changed dynamically through updates to the Deployment's Pod specification.

Stateless applications contrast stateful applications, which use persistent storage to save data and StatefulSets to deploy Pods with unique identities.

# Stateful Deployment 

Stateful Deployment:

A stateful deployment typically involves deploying applications that require persistent storage or maintain stateful data.
In this example, we'll create a stateful deployment for a WordPress application that uses a MySQL database.



